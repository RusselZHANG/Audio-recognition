DTW, MFCC
====================================
## 1. DTW: Dynamic Time Warping
---------------------------
DTW is designed for measure the simularities between two audios with different length sometimes poorly aligned, MFCC distance for words/sentences is not precises. \
Indicating whether two audio segment represent the same information. \

### Why DTM? 
* Two audio sequence containing same information may be in different time duration.
* Language speed may be different.
* Even in same words, different chars time occupation is different.
### Method：Time domain comparison
We suppose 2 signals: Q with n frames, C with m frames, for a single frame may correspond to several frames in the other. 
![DTW](https://github.com/RusselZHANG/Audio-recognition/blob/master/images/DTW.png)
* Compressing/Stretching the signal(simplest)
* Compute cost-matrix
* Dynamic programming: find the path of series of matching points(min cost) between two signals.
* Time warping function: w(qi,cj) define the mapping between the Q,C frames
* DTW(Q,C)= min{sqrt(w1+...+wk)/K} (K is the normalization factor to compute the identical distance)
* The minimum of DTW is the most similar warping

## 2. MFCC(Mel Frequency Cepstral Coefficient) Voice Feature:
---------------------------
The extracted formant (peak of spectrum) is the principle component who contains the unique information of voice identity. \
### Why MFCC: best voice feature for recognition and speaker separation
The human hearing concentrating on a series of specific frequency rather than the whole spectrum: a non-linear system response( distributed dense at low frequency and sparse in higher frequency). \
In mel domain, the perception is linear.
### How to compute:
* Pre-emphasis system: H(z) = 1- u/z u~(0.9,1.0)
* Discretization: single to frame
* Analysis window: perfect reconstruction, attenuate edge, emphaisze centrale (The role of overlapping) usually using hanning window with 50% overlapping
* X(f) = FFT(x(t)) = H(f)E(f)
* log(X(f))= log(H(f)) + log(E(f)) = log(Mel(X(f))) and Mel(f) = 2595lg(1+f/700) (from multiplication to addition)
* h[k]+e[k] = DCT(log(|X(f)|)) (h(k) is the spectrum envelop with poor variation, e(k) is spectrum details fluctuation(noise) oscillating in high-f
* h[k] = low pass filter (h[k]+e[k]) MFCC feature vector
![MFCC](https://github.com/RusselZHANG/Audio-recognition/blob/master/images/MFCC%20feature.PNG)



## 3. Code
* Parameters of DTW: dist, cost, acc, path[0],path[1]
* y = [0] * 5 ->>>[0,0,0,0,0]

Code finds [here](https://github.com/RusselZHANG/Audio-recognition/blob/master/2.%20MFCC%2C%20DTW.ipynb)

code copyright from： [你我学习互动园地](https://interactiveuandmetutorials.weebly.com/) 
