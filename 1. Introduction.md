Introduction
===================
# 1. Import library and Load a audio signal:
---------------------------
```python
import speech_recognition as sr
from playsound import playsound
playsound('audio_files\cnhello.mp3')
r = sr.Recognizer()
```
# 2. Audio signal sampling:
---------------------------

1D signal can be samples as a sequence function of time: value is amplitude then extracted audio snippet(声纹) \
CD quality sampling rate as **44.1khz**, source for recognition sampling rate as **16khz** \
Nyquist theorem: the sampling rate is 2 times higher than the highest frequency in the signal 

![Speech Recognition System](https://github.com/RusselZHANG/Audio-recognition/blob/master/images/system.JPG)
Conventionnal component of system:
* Acoustic model
* Pronounciation model(feature extraction from wav)
* Language model
# 3. Visualization：
-------------------------
* 1D amplitude signal(frequency/time)
* 2D spectrogram

# 4. Wav2char：
-------------------------
Find the corresponding character from sound slice, the result from current character prediction will influence the next value. \
Opertation: interrupt token, repeating token, post-processing

# 5. Code
* Define SR(7 models, wav2char)
* Necessary to use with...as to play speech_recognition.AudioData format
* gTTS(char2wav tool), gtts.save() need to use non pre-existing path
* Sphinx accuracy is not so good
* Chatrobot: Q&A system with listened words to trigger speak module
Code finds [here](https://github.com/RusselZHANG/Audio-recognition/blob/master/An%20introduction%20to%20speech%20recognition.ipynb)

code copyright from： [你我学习互动园地](https://interactiveuandmetutorials.weebly.com/) 




