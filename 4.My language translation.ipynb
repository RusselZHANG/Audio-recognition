{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diretory and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import spacy\n",
    "\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 專案的根目錄路徑\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# 置放訓練資料的目錄\n",
    "DATA_PATH = os.path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "# 訓練資料檔\n",
    "DATA_FILE = os.path.join(DATA_PATH, \"cmn-tw.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 19577\n"
     ]
    }
   ],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "\n",
    "input_characters = set() # 英文字符集\n",
    "target_characters = set() # 中文字符集\n",
    "\n",
    "\n",
    "\n",
    "#open txt file\n",
    "lines = open(DATA_FILE, mode=\"r\", encoding=\"utf-8\").read().split('\\n')\n",
    "np.random.shuffle(lines) \n",
    "print(type(lines),len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_en(text):\n",
    "   #将英语进行分词，颠倒顺序\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_cn(texts):\n",
    "    token = []\n",
    "    for text in texts:\n",
    "        for char in text:\n",
    "            if char not in token:\n",
    "                token.append(char)\n",
    "    return token\n",
    "\n",
    "# tokenize_cn(train_data.examples[1].trg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 19577\n",
      "Number of unique input tokens: 6766\n",
      "Number of unique output tokens: 2720\n",
      "Max sequence length for inputs: 165\n",
      "Max sequence length for outputs: 44\n"
     ]
    }
   ],
   "source": [
    "for line in lines[: len(lines)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    \n",
    "    # 我們使用“tab”作為“開始序列[SOS]”字符或目標，“\\n”作為“結束序列[EOS]”字符。 <-- **重要\n",
    "#     target_text = '\\t' + target_text + '\\n'\n",
    "    \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    for char in tokenize_en(input_text):       # English words corpus\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:      # Chinese words corpus\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)     \n",
    "            \n",
    "            \n",
    "input_characters = sorted(list(input_characters)) # 全部輸入的字符集\n",
    "target_characters = sorted(list(target_characters)) # 全部目標字符集\n",
    "\n",
    "num_encoder_tokens = len(input_characters) # 所有輸入字符的數量\n",
    "num_decoder_tokens = len(target_characters) # 所有輸目標字符的數量\n",
    "\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts]) # 最長的輸入句子長度\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts]) # 最長的目標句子長度\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create My own Translationdatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_Text(file_name,contant):\n",
    "    # file_name = 'test.txt'\n",
    "    with open(file_name,\"a+\") as f:\n",
    "        f.writelines(contant)\n",
    "        f.writelines(\"\\n\")\n",
    "\n",
    "import os\n",
    "\n",
    "file_write_obj = open(\"./data/src_en.txt\", 'w',encoding=\"utf-8\")\n",
    "# print(type(file_write_obj))\n",
    "for var in input_texts:\n",
    "#     print(var)\n",
    "    file_write_obj.writelines(var)\n",
    "    file_write_obj.write('\\n')\n",
    "file_write_obj.close()\n",
    "\n",
    "file_write_obj = open(\"./data/trg_cn.txt\", 'w',encoding=\"utf-8\")\n",
    "# print(type(file_write_obj))\n",
    "for var in target_texts:\n",
    "#     print(var)\n",
    "    file_write_obj.writelines(var)\n",
    "    file_write_obj.write('\\n')\n",
    "file_write_obj.close()\n",
    "\n",
    "names = ['train_src_en.txt','val_src_en.txt','test_src_en.txt','train_trg_cn.txt','val_trg_cn.txt','test_trg_cn.txt']\n",
    "\n",
    "def create_train_val_test_txt(names):\n",
    "    \n",
    "\n",
    "    for i,name in enumerate(names):\n",
    "        file = open('./data/'+ name, 'w',encoding=\"utf-8\")\n",
    "        if i<3:\n",
    "            data = input_texts.copy()\n",
    "        else:\n",
    "            data = target_texts.copy()\n",
    "\n",
    "        if name.split('_')[0] == 'train':\n",
    "            data = data[:18000]\n",
    "        elif name.split('_')[0] == 'val':\n",
    "            data = data[18000:19000]\n",
    "        else: data = data[19000:]\n",
    "\n",
    "        for var in data:\n",
    "    #     print(var)\n",
    "            file.writelines(var)\n",
    "            file.write('\\n')\n",
    "        file.close()\n",
    "        \n",
    "create_train_val_test_txt(names)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(sequential=True,\n",
    "            use_vocab=True,\n",
    "            tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(sequential=True, \n",
    "            use_vocab=True, \n",
    "            tokenize = tokenize_cn,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TranslationDataset instanciate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_data = TranslationDataset(path = './data/' , exts = ('src_en.txt','trg_cn.txt'), fields = (SRC,TRG))\n",
    "train_data, valid_data, test_data = T_data.splits(path = './data/' , exts = ('_src_en.txt','_trg_cn.txt'),fields = (SRC,TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 18000\n",
      "Number of validation examples: 1000\n",
      "Number of testing examples: 577\n",
      "<class 'torchtext.datasets.translation.TranslationDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['?', 'electricity', 'or', 'gas', 'by', 'cook', 'you', 'do'], 'trg': ['你', '煮', '飯', '用', '瓦', '斯', '還', '是', '電', '？']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[1]))\n",
    "# print(vars(SRC),'\\n\\n',vars(TRG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 3507\n",
      "Unique tokens in target (en) vocabulary: 2188\n"
     ]
    }
   ],
   "source": [
    "# 设置最小词频为2，当一个单词在数据集中出现次数小于2时会被转换为<unk>字符。\n",
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "\n",
    "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(SRC.vocabTRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://camo.githubusercontent.com/44a4c60ee9446a14effc6057a16c9f12b61102b5/68747470733a2f2f692e696d6775722e636f6d2f4e7a766c4733582e706e67\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  BucketIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines an iterator that loads batches of data from a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BucketIterator.splits(cls) 类方法，直接返回3个定义的 Iterator 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.iterator.BucketIterator"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)\n",
    "type(train_iterator)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "通过iter(iterator)获得了iterator迭代器\n",
    "iter() == iterator.__iter__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'dataset': <torchtext.datasets.translation.TranslationDataset object at 0x000001CC8CCE86D8>, 'fields': dict_keys(['src', 'trg']), 'input_fields': ['src', 'trg'], 'target_fields': [], 'src': tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  4,   4,   4,  ...,   4,   4,   4],\n",
      "        [ 62, 268,  29,  ..., 329,  74,   0],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0'), 'trg': tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  8,   5,   5,  ...,   9,  20,  15],\n",
      "        [136,  61,  29,  ...,  11,  21, 314],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')} \n",
      "\n",
      " <class 'torchtext.data.batch.Batch'>\n"
     ]
    }
   ],
   "source": [
    "batch = next(train_iterator.__iter__())\n",
    "print(vars(batch),'\\n\\n',type(batch ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic padding and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.batch.Batch'>\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iterator))\n",
    "print(type(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN structrue： Encoder + Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder: No need for output but C(t) and h(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim             # from one-hot sparse vector to word embedding relative vector\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)   \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)   # randomly initialization hid_dim\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "#       src:(sent_len, batch_size)\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "#       embedded:(sent_len, batch_size, emb_dim)\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "#       outputs:(sent_len, batch_size, hid_dim)\n",
    "#       hidden:(n_layers, batch_size, hid_dim)\n",
    "#       cell:(n_layers, batch_size, hid_dim)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim                                     # output of encoder\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "       \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.out = nn.Linear(hid_dim, output_dim)                        # linear layer full connection\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "#       input:(batch_size) -> input:(1, batch_size)\n",
    "        input = input.unsqueeze(0)\n",
    "#       embedded: (1, batch_size, emb_dim)     \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "#         hidden:(n_layers, batch size, hid_dim)\n",
    "#         cell:(n_layers, batch size, hid_dim)    \n",
    "#         output(1, batch_size, hid_dim)\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))       \n",
    "#         //prediction: (batch_size, output_dim)\n",
    "        prediction = self.out(output.squeeze(0))\n",
    "       \n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "#         //src: (sent_len, batch size)   \n",
    "#         //trg: (sent_len, batch size)    句子长度，batch_size\n",
    "        batch_size = trg.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "#       创建outputs张量存储Decoder的输出\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)   \n",
    "#       输入到Decoder网络的第一个字符是<sos>（句子开始标记）\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "#       注意前面的hidden、cell和后面的是不同的\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio           # 随机导师输入\n",
    "            top1 = output.max(1)[1]\n",
    "            input = (trg[t] if teacher_force else top1)\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initailization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 4\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "#使用to方法可以容易地将对象移动到不同的设备上（CPU或者GPU）\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3507 2188\n"
     ]
    }
   ],
   "source": [
    "print(INPUT_DIM,OUTPUT_DIM)   # number of token = onehot vector dimension\n",
    "# one-hot to word embedding INPUT_DIM -> ENC_EMB_DIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters initializaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(3507, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=4, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(2188, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=4, dropout=0.5)\n",
       "    (out): Linear(in_features=512, out_features=2188, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 18,341,772 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### criterion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "移除默认补齐<pad> token输入所带来的影响，在目标函数中不考虑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):       \n",
    "        src = batch.src\n",
    "        trg = batch.trg   \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "#         trg: (sent_len, batch size) -> (sent_len-1) * batch size)\n",
    "#         output: (sent_len, batch_size, output_dim) -> ((sent_len-1) * batch_size, output_dim))  \n",
    "        output = output[1:].view(-1, output.shape[-1]) \n",
    "        # 这里-1表示一个不确定的数，就是你如果不确定你想要reshape成几行，但是你很肯定要reshape成4列，那不确定的地方就可以写成-1\n",
    "        trg = trg[1:].view(-1)\n",
    "        # 由于trg每句话的开头都是标记符sos，为了提高准确度，output和trg的第一列将不参与计算损失。\n",
    "       \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)   # clip_grad_norm: 进行梯度裁剪，防止梯度爆炸。clip：梯度阈值\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation function: 只评价，不优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():   \n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            #0 : 关闭teacher forcing\n",
    "            output = model(src, trg, 0) \n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)           \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 30s\n",
      "\tTrain Loss: 2.859 | Train PPL:  17.451\n",
      "\t Val. Loss: 4.259 |  Val. PPL:  70.743\n",
      "Epoch: 02 | Time: 0m 30s\n",
      "\tTrain Loss: 2.800 | Train PPL:  16.447\n",
      "\t Val. Loss: 4.244 |  Val. PPL:  69.685\n",
      "Epoch: 03 | Time: 0m 31s\n",
      "\tTrain Loss: 2.732 | Train PPL:  15.359\n",
      "\t Val. Loss: 4.270 |  Val. PPL:  71.526\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 3\n",
    "CLIP = 1\n",
    "# 初始化为正无穷\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(valid_loss)\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 31\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(len(train_losses),len(val_losses))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "times = np.linspace(0,len(train_losses)-1,len(train_losses))\n",
    "\n",
    "plt.plot(times,train_losses,label = 'train',marker = 'o')\n",
    "plt.plot(times,val_losses,label = 'validation',marker = 'o')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 4.230975240468979\n"
     ]
    }
   ],
   "source": [
    "print(val_losses.index(min(val_losses)),min(val_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './model/'\n",
    "torch.save(model, model_dir+ 'NLP10.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.415 | Test PPL:  82.695 |\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(model_dir+ 'NLP10.pt')\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.iterator.BucketIterator'> [[   2    2    2 ...    2    2    2]\n",
      " [   4   10   10 ...    4    4  132]\n",
      " [ 505  497  701 ...  154  562 1954]\n",
      " ...\n",
      " [   3    3    1 ...    1    1    1]\n",
      " [   1    1    1 ...    1    1    1]\n",
      " [   1    1    1 ...    1    1    1]] (9, 128)\n"
     ]
    }
   ],
   "source": [
    "source = next(iter(test_iterator)).src.detach().cpu().numpy()\n",
    "target = next(iter(test_iterator)).trg.detach().cpu().numpy()\n",
    "\n",
    "print(type(test_iterator),source,np.shape(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(next(iter(test_iterator)).src,next(iter(test_iterator)).trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128, 2188)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 128]) torch.Size([10, 128])\n"
     ]
    }
   ],
   "source": [
    "source = next(iter(test_iterator)).src\n",
    "target = next(iter(test_iterator)).trg\n",
    "print(source.size(),target.size())\n",
    "\n",
    "TRG.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src: (sent_len, batch size)\n",
    "trg: (sent_len, batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.Counter"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(SRC.vocab.freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
